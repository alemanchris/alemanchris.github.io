
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Econometrics I</title><meta name="generator" content="MATLAB 9.9"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2022-02-25"><meta name="DC.source" content="s6.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Econometrics I</h1><pre>TA Christian Alem&aacute;n</pre><p><b>Session 6: Friday 25, February 2022</b></p><p><b>Activity 1: Hetoskedasticity</b></p><p><b>Simulating Hetoskedasticity</b></p><p><b>1.1: With Normal Errors:</b></p><p>Consider the model</p><p><img src="s6_eq05998836314605936363.png" alt="$y_{i} = \beta_{0}+\beta_{1}x_{i}+\epsilon_{i}$"></p><p><img src="s6_eq07474211892256132982.png" alt="$x\sim U[a,b]$">   and   <img src="s6_eq12676969628705722367.png" alt="$\epsilon \sim \mathcal{N}(0,\Sigma)$"></p><p><img src="s6_eq16487210253175665890.png" alt="$\Sigma=\left[\begin{array}{cccc} \sigma^{2}_{1}&amp;0&amp; \dots &amp;0 \\ 0&amp;\sigma^{2}_{2}&amp;\dots&amp;\vdots  \\ \vdots&amp;\vdots&amp;\ddots&amp;\vdots \\ 0&amp;\dots&amp;0&amp;\sigma^{2}_{n}  \end{array}\right]$"></p><pre class="codeinput"><span class="comment">% Housekeeping</span>
clear <span class="string">all</span>
close <span class="string">all</span>
clc
<span class="comment">% Set the seed</span>
rng(123)

<span class="comment">% Parameters</span>
par.beta0 = 1;      <span class="comment">% Intercept</span>
par.beta1 = 2;      <span class="comment">% Slope</span>
par.sigma = 1;      <span class="comment">% Standard deviation normal</span>
par.ub = 100;
par.lb = 0;
par.n = 200;

<span class="comment">% Simulate the Data Generating process</span>

aux_z = rand(par.n,1)*7;

<span class="comment">% The standard deviation of e is 1 plus 1.5z</span>

vars.eho = ((2)).*randn(par.n,1);
vars.ehe = ((20+10*aux_z)).*randn(par.n,1);
vars.x = unifrnd(par.lb,par.ub,par.n,1);

vars.y = par.beta0 +par.beta1.*vars.x +vars.ehe;
</pre><p>Plot our conditional residuals</p><pre class="codeinput">figure(1)
hold <span class="string">on</span>
plot(aux_z,vars.eho,<span class="string">'ko'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>)
yline(0)
xlabel(<span class="string">'$z$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
ylabel(<span class="string">'$\epsilon$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,16)
title(<span class="string">'Homoscedasticity'</span>)
figure(2)
hold <span class="string">on</span>
plot(aux_z,vars.ehe,<span class="string">'ko'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>)
yline(0)
xlabel(<span class="string">'$z$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
ylabel(<span class="string">'$\epsilon$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
title(<span class="string">'Heteroscedasticity'</span>)

<span class="comment">% Estimate OLS</span>
[beta,sigma,e,se] = my_ols(vars.y,[ones(par.n,1),vars.x]);
t=table(beta,se);
disp(t)
</pre><pre class="codeoutput">     beta       se   
    ______    _______

    15.411     8.1985
    1.7845    0.13496

</pre><img vspace="5" hspace="5" src="s6_01.png" alt=""> <img vspace="5" hspace="5" src="s6_02.png" alt=""> <p>Visual Inspection</p><pre class="codeinput">figure(3)
hold <span class="string">on</span>
plot(vars.x,vars.ehe,<span class="string">'ko'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>)
yline(0)
xlabel(<span class="string">'$x$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
ylabel(<span class="string">'$\epsilon$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
title(<span class="string">'Visual Inspection'</span>)
</pre><img vspace="5" hspace="5" src="s6_03.png" alt=""> <p><b>White Test</b></p><p><img src="s6_eq17153889864262985390.png" alt="$H_{0}:$"> Homoscedasticity</p><pre class="codeinput">[value, pvalue] = my_white(e,[ones(par.n,1),vars.x]);
t = table(pvalue);
disp(t)
disp(t)
<span class="keyword">if</span> pvalue&lt;0.05
    disp(<span class="string">'Reject Homoscedasticity'</span>)
<span class="keyword">else</span>
    disp(<span class="string">'Cannot Reject Homoscedasticity'</span>)
<span class="keyword">end</span>
</pre><pre class="codeoutput">     pvalue 
    ________

    0.042419

     pvalue 
    ________

    0.042419

Reject Homoscedasticity
</pre><p><b>Estimate GLS</b></p><pre class="codeinput">opt.het = 1;        <span class="comment">% Heteroskedasticity</span>
[beta_gls,e,se_gls] = my_gls(vars.y,[ones(par.n,1),vars.x],opt);

betas_1 =  [beta(2);beta_gls(2)];
method = {<span class="string">'OLS'</span>;<span class="string">'FGLS'</span>};
s_err = [se(2);se_gls(2)];
t = table(method,betas_1,s_err);
disp(t)
</pre><p>Lets Compute Bootstrap SE</p><pre class="codeinput">par.B = 1000;<span class="comment">%</span>
par.K = 2;
hbeta_sample =NaN(par.B,par.K);
rng(234)
<span class="keyword">for</span> i = 1:par.B

    I_sample = ceil(par.n*rand(1,par.n));
    ysample = vars.y(I_sample);
    xsample(:,1) = vars.x(I_sample,1);

    hbeta_sample(i,:)  = ([ones(par.n,1),xsample]\ysample)';
<span class="keyword">end</span>
diff = hbeta_sample-repmat(beta',par.B,1);
bootVCV = diff'*diff/par.B;
vars.SEbeta_hat_boot = sqrt(diag(bootVCV));

betas_1 =  [beta(2);beta_gls(2);mean(hbeta_sample(:,2))];
method = {<span class="string">'OLS'</span>;<span class="string">'FGLS'</span>;<span class="string">'Bootstrap'</span>};
s_err = [se(2);se_gls(2);vars.SEbeta_hat_boot(2)];
t = table(method,betas_1,s_err);
disp(t)
</pre><pre class="codeoutput">       method        betas_1     s_err  
    _____________    _______    ________

    {'OLS'      }    1.7845      0.13496
    {'FGLS'     }    1.7974     0.024771
    {'Bootstrap'}    1.7807      0.14531

</pre><p><b>1.2: With Uniform Errors:</b></p><p>Consider the model</p><p><img src="s6_eq05998836314605936363.png" alt="$y_{i} = \beta_{0}+\beta_{1}x_{i}+\epsilon_{i}$"></p><p><img src="s6_eq07474211892256132982.png" alt="$x\sim U[a,b]$">   and   <img src="s6_eq11889314767410893101.png" alt="$\epsilon \sim U[-z,z]$"></p><p>Estimate OLS</p><pre class="codeinput">par.ub = 100;
par.lb = 0;
aux_z = rand(par.n,1).*7;

vars.ehe = ((20+10*aux_z)).*(rand(par.n,1)-0.5);
vars.x(:,1) = unifrnd(par.lb,par.ub,par.n,1);
vars.x(:,2) = aux_z;
vars.y = par.beta0 +par.beta1.*vars.x(:,1) +par.beta1.*vars.x(:,2) +vars.ehe;

[beta,sigma,e,se] = my_ols(vars.y,[ones(par.n,1),vars.x]);
</pre><p>Visual Inspection</p><pre class="codeinput">figure(4)
hold <span class="string">on</span>
plot(vars.x(:,2),vars.ehe,<span class="string">'ko'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>)
yline(0)
xlabel(<span class="string">'$x$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
ylabel(<span class="string">'$\epsilon$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
title(<span class="string">'Visual Inspection'</span>)
</pre><img vspace="5" hspace="5" src="s6_04.png" alt=""> <p><b>White Test</b></p><p><img src="s6_eq17153889864262985390.png" alt="$H_{0}:$"> Homoscedasticity</p><pre class="codeinput">[value, pvalue] = my_white(e,[ones(par.n,1),vars.x]);
t = table(pvalue);
disp(t)
<span class="keyword">if</span> pvalue&lt;0.05
    disp(<span class="string">'Reject Homoscedasticity'</span>)
<span class="keyword">else</span>
    disp(<span class="string">'Cannot Reject Homoscedasticity'</span>)
<span class="keyword">end</span>
</pre><pre class="codeoutput">      pvalue  
    __________

    1.7313e-09

Reject Homoscedasticity
</pre><p>Estimate GLS and Bootstrap SE</p><pre class="codeinput">[beta_gls,~,se_gls] = my_gls(vars.y,[ones(par.n,1),vars.x],opt);

par.B = 1000;<span class="comment">%</span>
par.K = 3;
hbeta_sample =NaN(par.B,par.K);
rng(234)
<span class="keyword">for</span> i = 1:par.B

    I_sample = ceil(par.n*rand(1,par.n));
    ysample = vars.y(I_sample);
    xsample = vars.x(I_sample,:);

    hbeta_sample(i,:)  = ([ones(par.n,1),xsample]\ysample)';
<span class="keyword">end</span>
diff = hbeta_sample-repmat(beta',par.B,1);
bootVCV = diff'*diff/par.B;
vars.SEbeta_hat_boot = sqrt(diag(bootVCV));

betas_1 =  [beta(2);beta_gls(2);mean(hbeta_sample(:,2))];
method = {<span class="string">'OLS'</span>;<span class="string">'FGLS'</span>;<span class="string">'Bootstrap'</span>};
s_err = [se(2);se_gls(2);vars.SEbeta_hat_boot(2)];
t = table(method,betas_1,s_err);
disp(t)
</pre><pre class="codeoutput">       method        betas_1      s_err  
    _____________    _______    _________

    {'OLS'      }     2.019        0.0383
    {'FGLS'     }    2.0087     0.0056683
    {'Bootstrap'}    2.0214      0.036392

</pre><p><b>Activity 2: Autocorrelated Errors</b></p><p><b>Simulating AR(1) errors</b></p><p>Consider the model</p><p><img src="s6_eq05998836314605936363.png" alt="$y_{i} = \beta_{0}+\beta_{1}x_{i}+\epsilon_{i}$"></p><p><img src="s6_eq07474211892256132982.png" alt="$x\sim U[a,b]$">   and   <img src="s6_eq07945187489341872219.png" alt="$\epsilon_{i} = \rho\epsilon_{i-1}+u$"></p><p>and <img src="s6_eq06658811080705620356.png" alt="$u \sim \mathcal{N}(0,\sigma^{2})$"></p><p><img src="s6_eq11295922202423636942.png" alt="$\Sigma=\left[\begin{array}{ccccc} 1&amp;\rho&amp; \rho^{2}&amp; \dots &amp;\rho^{n-1} \\ \rho&amp;1&amp;\dots&amp;\dots&amp;\rho^{n-2}  \\ \rho^{2}&amp;\vdots&amp;1&amp;\vdots&amp;\vdots \\ \vdots&amp;\vdots&amp;\vdots&amp;1&amp;\rho \\ \rho^{n-1}&amp;\dots&amp;\dots&amp;\dots&amp;1  \end{array}\right]$"></p><pre class="codeinput">par.rho = 0.7;
vars.eau = NaN(par.n,1);
vars.eau(1,1) = randn(1,1)/sqrt(1-par.rho^2);  <span class="comment">% The trend of the AR(1) process</span>
<span class="keyword">for</span> i = 2:par.n
    rng(12300+i)
  vars.eau(i,1) = par.rho*vars.eau(i-1,1) + 0.1*randn(1,1); <span class="comment">%</span>
<span class="keyword">end</span>
vars.x = unifrnd(par.lb,par.ub,par.n,1);
vars.y = par.beta0 +par.beta1.*vars.x +vars.eau;

[beta,sigma,e,se] = my_ols(vars.y,[ones(par.n,1),vars.x]);
</pre><p>Visual Inspection</p><pre class="codeinput">figure(5)
hold <span class="string">on</span>
plot(e(2:end),e(1:end-1),<span class="string">'ko'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>)
yline(0)
xlabel(<span class="string">'$\epsilon_{t-1}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
ylabel(<span class="string">'$\epsilon_{t}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'Fontsize'</span>,16)
title(<span class="string">'Visual Inspection'</span>)
</pre><img vspace="5" hspace="5" src="s6_05.png" alt=""> <p><b>DW</b> Durbin Watson</p><p><img src="s6_eq17153889864262985390.png" alt="$H_{0}:$"> No Autocorrelation</p><pre class="codeinput">pvalue = dwtest(e,[ones(par.n,1),vars.x]);
t = table(pvalue);
disp(t)
<span class="keyword">if</span> pvalue&lt;0.05
    disp(<span class="string">'Reject Null: there is autocorrelation'</span>)
<span class="keyword">else</span>
    disp(<span class="string">'Cannot Reject Null; There is no autocorrelation'</span>)
<span class="keyword">end</span>
</pre><pre class="codeoutput">      pvalue  
    __________

    1.1739e-30

Reject Null: there is autocorrelation
</pre><p><b>Estimate GLS and Bootstrap SE</b></p><pre class="codeinput">opt.het = 1;
[beta_gls,e,se_gls] = my_gls(vars.y,[ones(par.n,1),vars.x],opt);
par.B = 1000;<span class="comment">%</span>
par.K = 2;
hbeta_sample =NaN(par.B,par.K);
rng(234)
<span class="keyword">for</span> i = 1:par.B

    I_sample = ceil(par.n*rand(1,par.n));
    ysample = vars.y(I_sample);
    xsample = vars.x(I_sample,:);

    hbeta_sample(i,:)  = ([ones(par.n,1),xsample]\ysample)';
<span class="keyword">end</span>
diff = hbeta_sample-repmat(beta',par.B,1);
bootVCV = diff'*diff/par.B;
vars.SEbeta_hat_boot = sqrt(diag(bootVCV));
betas_1 =  [beta(2);beta_gls(2);mean(hbeta_sample(:,2))];
method = {<span class="string">'OLS'</span>;<span class="string">'FGLS'</span>;<span class="string">'Bootstrap'</span>};
s_err = [se(2);se_gls(2);vars.SEbeta_hat_boot(2)];
t = table(method,betas_1,s_err);
disp(t)
</pre><p>End of Code</p><pre class="codeinput"><span class="comment">%---------------------------------------------------------</span>
<span class="keyword">function</span> [beta,e,se] = my_gls(y,x,opt)
<span class="comment">%{
</span><span class="comment">This function computes GLS estimates and
</span><span class="comment">its standard errors
</span><span class="comment">inputs: y dependent var
</span><span class="comment">        x independent vars
</span><span class="comment">outputs: beta   OLS coefficients
</span><span class="comment">         sigma  Estimator or variance of error
</span><span class="comment">         e      Backed residuals
</span><span class="comment">         se     Standard Errors
</span><span class="comment">%}
</span>    n = size(x,1);
    <span class="keyword">if</span> opt.het==1
        <span class="comment">% Tradicional heteroskedasticity</span>
        [~,~,e_ols] = my_ols(y, x);
        e_ols = e_ols.^2;
        C = diag(1./ sqrt(e_ols));
        [beta,~,e,se] = my_ols(C*y, C*x);
    <span class="keyword">else</span>
        <span class="comment">% AR(1) Errors</span>
        [~,~,e_ols] = my_ols(y, x);

        <span class="comment">% estimation of AR(1) coefficient</span>
        ey = e_ols(2:n);
        ex = e_ols(1:n-1);
        rho = ex\ey;            <span class="comment">% Estimating the autocorrelation coeff</span>
        e_auto = ey-ex*rho;
        var_e = var(e_auto);

        <span class="comment">%factor = eye(n).*var_e./(1-rho^2);     % Cancels out</span>
        sigma_e = eye(n);
        <span class="keyword">for</span> i = 1:n
            <span class="keyword">for</span> j = i+1:n
                sigma_e(i,j) = rho^(j-i);
                sigma_e(j,i) = sigma_e(i,j);
            <span class="keyword">end</span>
        <span class="keyword">end</span>
        <span class="comment">%sigma_e = factor.*sigma_e;</span>
        C = chol(sigma_e);
        [beta,~,e,se] = my_ols(C*y, C*x);
    <span class="keyword">end</span> <span class="comment">% end if</span>
<span class="keyword">end</span>
<span class="comment">%---------------------------------------------------------</span>
<span class="keyword">function</span> [beta,sigma,e,se] = my_ols(y,x)
<span class="comment">%{
</span><span class="comment">This function computes OLS estiamtes and
</span><span class="comment">its standard errors
</span><span class="comment">inputs: y dependent var
</span><span class="comment">        x independent vars
</span><span class="comment">outputs: beta   OLS coefficients
</span><span class="comment">         sigma  Estimator or variance of error
</span><span class="comment">         e      Backed residuals
</span><span class="comment">         se     Standard Errors
</span><span class="comment">%}
</span>    n = size(x,1);
    beta = x\y;
    sigma = (y-x*beta)'*(y-x*beta)/(n-rank(x));
    e = y - x*beta;
    VCV = (e'*e)/n*inv(x'*x);
    se = sqrt(diag(VCV));
<span class="keyword">end</span>
<span class="comment">%---------------------------------------------------------</span>
<span class="keyword">function</span> [value, pvalue] = my_white(e, x)
<span class="comment">%{
</span><span class="comment"> White's test for heteroscedasticity
</span><span class="comment"> Input:
</span><span class="comment">	e: Residuals
</span><span class="comment">	x: Independent Variables
</span><span class="comment">%}
</span>	n = size(e,1);
	k = size(x,2) - 1;
	[~,~,e_ols] =my_ols(e.^2,x);
    TSS = e.^2 - mean(e.^2);
	TSS = TSS' * TSS;
	ESS = e_ols' * e_ols;
	rsq = 1 - ESS / TSS;  <span class="comment">% the r-square auxiliary</span>
	value = n*rsq;                  <span class="comment">% Statistic</span>
	pvalue = 1 - chi2cdf(value,k);  <span class="comment">% Value</span>
<span class="keyword">end</span>
</pre><pre class="codeoutput">     method     betas_1     s_err  
    ________    _______    ________

    {'OLS' }    1.7845      0.13496
    {'FGLS'}    1.7974     0.024771

</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Econometrics I 
%  TA Christian AlemÃ¡n
% 
% *Session 6: Friday 25, February 2022*
%
% *Activity 1: Hetoskedasticity* 
%
% *Simulating Hetoskedasticity*
%
% *1.1: With Normal Errors:*
%
% Consider the model
%
% $y_{i} = \beta_{0}+\beta_{1}x_{i}+\epsilon_{i}$
%
% $x\sim U[a,b]$   and   $\epsilon \sim \mathcal{N}(0,\Sigma)$
%
% $\Sigma=\left[\begin{array}{cccc} \sigma^{2}_{1}&0& \dots &0 \\ 0&\sigma^{2}_{2}&\dots&\vdots  \\ \vdots&\vdots&\ddots&\vdots \\ 0&\dots&0&\sigma^{2}_{n}  \end{array}\right]$


% Housekeeping
clear all
close all
clc
% Set the seed
rng(123)

% Parameters
par.beta0 = 1;      % Intercept
par.beta1 = 2;      % Slope
par.sigma = 1;      % Standard deviation normal
par.ub = 100;
par.lb = 0; 
par.n = 200;

% Simulate the Data Generating process

aux_z = rand(par.n,1)*7;

% The standard deviation of e is 1 plus 1.5z 

vars.eho = ((2)).*randn(par.n,1);
vars.ehe = ((20+10*aux_z)).*randn(par.n,1);
vars.x = unifrnd(par.lb,par.ub,par.n,1);

vars.y = par.beta0 +par.beta1.*vars.x +vars.ehe;

%% 
% Plot our conditional residuals

figure(1)
hold on
plot(aux_z,vars.eho,'ko','MarkerFaceColor','k')
yline(0)
xlabel('$z$','interpreter','latex','Fontsize',16)
ylabel('$\epsilon$','interpreter','latex','FontSize',16)
title('Homoscedasticity')
figure(2)
hold on
plot(aux_z,vars.ehe,'ko','MarkerFaceColor','k')
yline(0)
xlabel('$z$','interpreter','latex','Fontsize',16)
ylabel('$\epsilon$','interpreter','latex','Fontsize',16)
title('Heteroscedasticity')

% Estimate OLS
[beta,sigma,e,se] = my_ols(vars.y,[ones(par.n,1),vars.x]);
t=table(beta,se);
disp(t)

%%
% Visual Inspection
figure(3)
hold on
plot(vars.x,vars.ehe,'ko','MarkerFaceColor','k')
yline(0)
xlabel('$x$','interpreter','latex','Fontsize',16)
ylabel('$\epsilon$','interpreter','latex','Fontsize',16)
title('Visual Inspection')

%%
% *White Test*
%
% $H_{0}:$ Homoscedasticity

[value, pvalue] = my_white(e,[ones(par.n,1),vars.x]);
t = table(pvalue);
disp(t)
disp(t)
if pvalue<0.05
    disp('Reject Homoscedasticity')
else
    disp('Cannot Reject Homoscedasticity')
end

%%
% *Estimate GLS*
opt.het = 1;        % Heteroskedasticity
[beta_gls,e,se_gls] = my_gls(vars.y,[ones(par.n,1),vars.x],opt);

betas_1 =  [beta(2);beta_gls(2)];
method = {'OLS';'FGLS'};
s_err = [se(2);se_gls(2)];
t = table(method,betas_1,s_err);
disp(t)


%%
% Lets Compute Bootstrap SE
%
par.B = 1000;%
par.K = 2;
hbeta_sample =NaN(par.B,par.K);
rng(234)
for i = 1:par.B   
    
    I_sample = ceil(par.n*rand(1,par.n));
    ysample = vars.y(I_sample);
    xsample(:,1) = vars.x(I_sample,1);    
    
    hbeta_sample(i,:)  = ([ones(par.n,1),xsample]\ysample)';
end
diff = hbeta_sample-repmat(beta',par.B,1);
bootVCV = diff'*diff/par.B;
vars.SEbeta_hat_boot = sqrt(diag(bootVCV));

betas_1 =  [beta(2);beta_gls(2);mean(hbeta_sample(:,2))];
method = {'OLS';'FGLS';'Bootstrap'};
s_err = [se(2);se_gls(2);vars.SEbeta_hat_boot(2)];
t = table(method,betas_1,s_err);
disp(t)

%%
% *1.2: With Uniform Errors:*
%
% Consider the model
%
% $y_{i} = \beta_{0}+\beta_{1}x_{i}+\epsilon_{i}$
%
% $x\sim U[a,b]$   and   $\epsilon \sim U[-z,z]$
%
% Estimate OLS
par.ub = 100;
par.lb = 0; 
aux_z = rand(par.n,1).*7;

vars.ehe = ((20+10*aux_z)).*(rand(par.n,1)-0.5);
vars.x(:,1) = unifrnd(par.lb,par.ub,par.n,1);
vars.x(:,2) = aux_z;
vars.y = par.beta0 +par.beta1.*vars.x(:,1) +par.beta1.*vars.x(:,2) +vars.ehe;

[beta,sigma,e,se] = my_ols(vars.y,[ones(par.n,1),vars.x]);

%%
% Visual Inspection
figure(4)
hold on
plot(vars.x(:,2),vars.ehe,'ko','MarkerFaceColor','k')
yline(0)
xlabel('$x$','interpreter','latex','Fontsize',16)
ylabel('$\epsilon$','interpreter','latex','Fontsize',16)
title('Visual Inspection')

%%
% *White Test*
%
% $H_{0}:$ Homoscedasticity

[value, pvalue] = my_white(e,[ones(par.n,1),vars.x]);
t = table(pvalue);
disp(t)
if pvalue<0.05
    disp('Reject Homoscedasticity')
else
    disp('Cannot Reject Homoscedasticity')
end

%%
% Estimate GLS and Bootstrap SE

[beta_gls,~,se_gls] = my_gls(vars.y,[ones(par.n,1),vars.x],opt);

par.B = 1000;%
par.K = 3;
hbeta_sample =NaN(par.B,par.K);
rng(234)
for i = 1:par.B   
    
    I_sample = ceil(par.n*rand(1,par.n));
    ysample = vars.y(I_sample);
    xsample = vars.x(I_sample,:);    
    
    hbeta_sample(i,:)  = ([ones(par.n,1),xsample]\ysample)';
end
diff = hbeta_sample-repmat(beta',par.B,1);
bootVCV = diff'*diff/par.B;
vars.SEbeta_hat_boot = sqrt(diag(bootVCV));

betas_1 =  [beta(2);beta_gls(2);mean(hbeta_sample(:,2))];
method = {'OLS';'FGLS';'Bootstrap'};
s_err = [se(2);se_gls(2);vars.SEbeta_hat_boot(2)];
t = table(method,betas_1,s_err);
disp(t)

%% 
% *Activity 2: Autocorrelated Errors*
%
% *Simulating AR(1) errors*
%
% Consider the model
%
% $y_{i} = \beta_{0}+\beta_{1}x_{i}+\epsilon_{i}$
%
% $x\sim U[a,b]$   and   $\epsilon_{i} = \rho\epsilon_{i-1}+u$  
%
% and $u \sim \mathcal{N}(0,\sigma^{2})$
%
% $\Sigma=\left[\begin{array}{ccccc} 1&\rho& \rho^{2}& \dots &\rho^{n-1} \\ \rho&1&\dots&\dots&\rho^{n-2}  \\ \rho^{2}&\vdots&1&\vdots&\vdots \\ \vdots&\vdots&\vdots&1&\rho \\ \rho^{n-1}&\dots&\dots&\dots&1  \end{array}\right]$

par.rho = 0.7;
vars.eau = NaN(par.n,1);
vars.eau(1,1) = randn(1,1)/sqrt(1-par.rho^2);  % The trend of the AR(1) process
for i = 2:par.n
    rng(12300+i)
  vars.eau(i,1) = par.rho*vars.eau(i-1,1) + 0.1*randn(1,1); % 
end
vars.x = unifrnd(par.lb,par.ub,par.n,1);
vars.y = par.beta0 +par.beta1.*vars.x +vars.eau;

[beta,sigma,e,se] = my_ols(vars.y,[ones(par.n,1),vars.x]);

%%
% Visual Inspection
figure(5)
hold on
plot(e(2:end),e(1:end-1),'ko','MarkerFaceColor','k')
yline(0)
xlabel('$\epsilon_{t-1}$','interpreter','latex','Fontsize',16)
ylabel('$\epsilon_{t}$','interpreter','latex','Fontsize',16)
title('Visual Inspection')

%%
% *DW* Durbin Watson
%
% $H_{0}:$ No Autocorrelation

pvalue = dwtest(e,[ones(par.n,1),vars.x]);
t = table(pvalue);
disp(t)
if pvalue<0.05
    disp('Reject Null: there is autocorrelation')
else
    disp('Cannot Reject Null; There is no autocorrelation')
end

%%
% *Estimate GLS and Bootstrap SE*

opt.het = 1;        
[beta_gls,e,se_gls] = my_gls(vars.y,[ones(par.n,1),vars.x],opt);
par.B = 1000;%
par.K = 2;
hbeta_sample =NaN(par.B,par.K);
rng(234)
for i = 1:par.B   
    
    I_sample = ceil(par.n*rand(1,par.n));
    ysample = vars.y(I_sample);
    xsample = vars.x(I_sample,:);    
    
    hbeta_sample(i,:)  = ([ones(par.n,1),xsample]\ysample)';
end
diff = hbeta_sample-repmat(beta',par.B,1);
bootVCV = diff'*diff/par.B;
vars.SEbeta_hat_boot = sqrt(diag(bootVCV));
betas_1 =  [beta(2);beta_gls(2);mean(hbeta_sample(:,2))];
method = {'OLS';'FGLS';'Bootstrap'};
s_err = [se(2);se_gls(2);vars.SEbeta_hat_boot(2)];
t = table(method,betas_1,s_err);
disp(t)


%%
% End of Code

%%
%REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
function [beta,e,se] = my_gls(y,x,opt)
%{
This function computes GLS estimates and 
its standard errors
inputs: y dependent var
        x independent vars
outputs: beta   OLS coefficients
         sigma  Estimator or variance of error
         e      Backed residuals
         se     Standard Errors
%}
    n = size(x,1); 
    if opt.het==1
        % Tradicional heteroskedasticity
        [~,~,e_ols] = my_ols(y, x);
        e_ols = e_ols.^2;
        C = diag(1./ sqrt(e_ols));
        [beta,~,e,se] = my_ols(C*y, C*x);
    else
        % AR(1) Errors
        [~,~,e_ols] = my_ols(y, x);

        % estimation of AR(1) coefficient
        ey = e_ols(2:n);
        ex = e_ols(1:n-1);
        rho = ex\ey;            % Estimating the autocorrelation coeff
        e_auto = ey-ex*rho;
        var_e = var(e_auto);

        %factor = eye(n).*var_e./(1-rho^2);     % Cancels out
        sigma_e = eye(n);
        for i = 1:n
            for j = i+1:n
                sigma_e(i,j) = rho^(j-i);
                sigma_e(j,i) = sigma_e(i,j);
            end
        end
        %sigma_e = factor.*sigma_e;
        C = chol(sigma_e);
        [beta,~,e,se] = my_ols(C*y, C*x);
    end % end if
end
%REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
function [beta,sigma,e,se] = my_ols(y,x)
%{
This function computes OLS estiamtes and 
its standard errors
inputs: y dependent var
        x independent vars
outputs: beta   OLS coefficients
         sigma  Estimator or variance of error
         e      Backed residuals
         se     Standard Errors
%}
    n = size(x,1);
    beta = x\y;
    sigma = (y-x*beta)'*(y-x*beta)/(n-rank(x));
    e = y - x*beta;
    VCV = (e'*e)/n*inv(x'*x);
    se = sqrt(diag(VCV));
end
%REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
function [value, pvalue] = my_white(e, x)
%{
 White's test for heteroscedasticity
 Input:
	e: Residuals
	x: Independent Variables
%}
	n = size(e,1);
	k = size(x,2) - 1;	
	[~,~,e_ols] =my_ols(e.^2,x);
    TSS = e.^2 - mean(e.^2);
	TSS = TSS' * TSS;
	ESS = e_ols' * e_ols;
	rsq = 1 - ESS / TSS;  % the r-square auxiliary	
	value = n*rsq;                  % Statistic
	pvalue = 1 - chi2cdf(value,k);  % Value
end
##### SOURCE END #####
--></body></html>